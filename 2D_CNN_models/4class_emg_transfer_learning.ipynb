{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import st_remux as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# highpath = 'datasets/high.csv'\n",
    "# lowpath = 'datasets/none.csv'\n",
    "# hi = st.raw_to_arr(high, fs, win_len, 0)\n",
    "# lo = st.raw_to_arr(low, fs, win_len, 0)\n",
    "highdir = 'datasets/high'\n",
    "meddir = 'datasets/med'\n",
    "lowdir = 'datasets/low'\n",
    "nonedir = 'datasets/none'\n",
    "\n",
    "\n",
    "\n",
    "fs = 4000\n",
    "win_len = 40\n",
    "\n",
    "use_filter = 0   # weird results if we use python filtering\n",
    "\n",
    "use_matlab_backend = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using native backend\n"
     ]
    }
   ],
   "source": [
    "if use_matlab_backend:\n",
    "    print('Using MATLAB signal processing backend')\n",
    "    # high_dir = 'datasets/high/'\n",
    "    # low_dir = 'datasets/low/'\n",
    "\n",
    "    high_dir = 'C:/Users/Geoffrey/Documents/MATLAB/S transform time frequency/high/'\n",
    "    low_dir = 'C:/Users/Geoffrey/Documents/MATLAB/S transform time frequency/low/'\n",
    "\n",
    "    def generate_3darray(directory):\n",
    "        files = os.listdir(directory)\n",
    "        dims = np.genfromtxt(directory + files[0], delimiter=',').shape\n",
    "        length = len(files)\n",
    "        arr = np.zeros((length, dims[0], dims[1]))\n",
    "\n",
    "        for idx, val in enumerate(files):\n",
    "            arr[idx] = np.genfromtxt(directory + val, delimiter=',')\n",
    "\n",
    "        return arr\n",
    "\n",
    "    hi = generate_3darray(high_dir)\n",
    "    lo = generate_3darray(low_dir)\n",
    "    \n",
    "else: \n",
    "    print('Using native backend')\n",
    "    hi = st.raw_to_arr(highdir, fs, win_len, 0)\n",
    "    med = st.raw_to_arr(meddir, fs, win_len, 0)\n",
    "    lo = st.raw_to_arr(lowdir, fs, win_len, 0)\n",
    "    none = st.raw_to_arr(nonedir, fs, win_len, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23470, 16, 40)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((hi, med, lo, none))\n",
    "d= X.shape\n",
    "print(d)\n",
    "\n",
    "hi_Y = np.ones(len(hi), dtype=int) * 3\n",
    "med_Y = np.ones(len(med), dtype=int) * 2\n",
    "lo_Y = np.ones(len(lo), dtype=int) * 1\n",
    "none_Y = np.zeros(len(none), dtype=int)\n",
    "\n",
    "Y = np.concatenate((hi_Y, med_Y, lo_Y, none_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (21123, 16, 40) (21123,)\n",
      "Testing data shape:  (2347, 16, 40) (2347,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape: ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape: ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs:  4\n",
      "Output classes:  [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(train_Y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs: ', nClasses)\n",
    "print('Output classes: ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Ground Truth: 2')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,2])\n",
    "\n",
    "# Display first image in training set\n",
    "plt.subplot(121)\n",
    "plt.pcolormesh(train_X[0,:,:], cmap='jet')\n",
    "plt.title(\"Ground Truth: {}\".format(train_Y[0]))\n",
    "\n",
    "# Display second image in testing set\n",
    "plt.subplot(122)\n",
    "plt.pcolormesh(test_X[1], cmap='jet')\n",
    "plt.title(\"Ground Truth: {}\".format(test_Y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16898, 16, 40, 1), (2347, 16, 40, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydim = train_X[0].shape[0]\n",
    "xdim = train_X[0].shape[1]\n",
    "train_X = train_X.reshape(-1, ydim, xdim, 1)\n",
    "test_X = test_X.reshape(-1, ydim, xdim, 1)\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label:  0\n",
      "After conversion to one-hot:  [1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# See the difference?\n",
    "print('Original label: ', train_Y[0])\n",
    "print('After conversion to one-hot: ', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21123, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16898, 16, 40, 1), (4225, 16, 40, 1), (16898, 4), (4225, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Here I split original training data to sub-training (80%) and validation data (20%)\n",
    "train_X, valid_X, train_label, valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
    "\n",
    "# Check the data size whether it is as per tensorflow and VGG19 requirement\n",
    "train_X.shape, valid_X.shape, train_label.shape, valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; got `input_shape=(16, 40, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d2511e17800a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create the base model of VGG19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvgg19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/keras/applications/vgg19.py\u001b[0m in \u001b[0;36mVGG19\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvgg19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/keras_applications/vgg19.py\u001b[0m in \u001b[0;36mVGG19\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                       weights=weights)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/keras_applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                     raise ValueError('The input must have 3 channels; got '\n\u001b[0;32m--> 316\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    317\u001b[0m                 if ((input_shape[0] is not None and input_shape[0] < min_size) or\n\u001b[1;32m    318\u001b[0m                    (input_shape[1] is not None and input_shape[1] < min_size)):\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; got `input_shape=(16, 40, 1)`"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG19\n",
    "\n",
    "# Create the base model of VGG19\n",
    "vgg19 = VGG19(weights='imagenet', include_top=False, input_shape = (16, 40, 1), classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "# Preprocessing the input \n",
    "train_X = preprocess_input(train_X)\n",
    "valid_X = preprocess_input(valid_X)\n",
    "test_X = preprocess_input(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = vgg19.predict(np.array(train_X), batch_size=256, verbose=1)\n",
    "test_features = vgg19.predict(np.array(test_X), batch_size=256, verbose=1)\n",
    "val_features = vgg19.predict(np.array(valid_X), batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"train_features\", train_features, train_label)\n",
    "np.savez(\"test_features\", test_features, test_Y_one_hot)\n",
    "np.savez(\"val_features\", val_features, valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape, \"\\n\",  test_features.shape, \"\\n\", val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (48000, 4*4*512))\n",
    "test_features = np.reshape(test_features, (10000, 4*4*512))\n",
    "val_features = np.reshape(val_features, (12000, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "# Add Dense and Dropout layers on top of VGG19 pre-trained\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_features, train_label,\n",
    "          batch_size=256,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(val_features, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
