{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import st_remux as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "highpath = 'EMG_data/high_fatigue_raw.csv'\n",
    "lowpath = 'EMG_data/low_fatigue_raw.csv'\n",
    "\n",
    "fs = 4000\n",
    "win_len = 40\n",
    "\n",
    "use_filter = 0   # weird results if we use python filtering\n",
    "\n",
    "use_matlab_backend = 0\n",
    "\n",
    "high = np.genfromtxt(highpath, delimiter=',')\n",
    "low = np.genfromtxt(lowpath, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using native backend\n"
     ]
    }
   ],
   "source": [
    "if use_matlab_backend:\n",
    "    print('Using MATLAB signal processing backend')\n",
    "    # high_dir = 'datasets/high/'\n",
    "    # low_dir = 'datasets/low/'\n",
    "\n",
    "    high_dir = 'EMG_data/power_spectrum_for_cnn_input/high/'\n",
    "    low_dir = 'EMG_data/power_spectrum_for_cnn_input/low/'\n",
    "\n",
    "    def generate_3darray(directory):\n",
    "        files = os.listdir(directory)\n",
    "        dims = np.genfromtxt(directory + files[0], delimiter=',').shape\n",
    "        length = len(files)\n",
    "        arr = np.zeros((length, dims[0], dims[1]))\n",
    "\n",
    "        for idx, val in enumerate(files):\n",
    "            arr[idx] = np.genfromtxt(directory + val, delimiter=',')\n",
    "\n",
    "        return arr\n",
    "\n",
    "    hi = generate_3darray(high_dir)\n",
    "    lo = generate_3darray(low_dir)\n",
    "    \n",
    "else: \n",
    "    print('Using native backend')\n",
    "    hi = st.raw_to_arr(high, fs, win_len, 0)\n",
    "    lo = st.raw_to_arr(low, fs, win_len, 0)\n",
    "\n",
    "X = np.concatenate((hi, lo))\n",
    "\n",
    "hi_Y = np.ones(len(hi), dtype=int)\n",
    "lo_Y = np.zeros(len(lo), dtype=int)\n",
    "\n",
    "Y = np.concatenate((hi_Y, lo_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (3681, 16, 40) (3681,)\n",
      "Testing data shape:  (410, 16, 40) (410,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape: ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape: ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs:  2\n",
      "Output classes:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(train_Y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs: ', nClasses)\n",
    "print('Output classes: ', classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Ground Truth: 1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,2])\n",
    "\n",
    "# Display first image in training set\n",
    "plt.subplot(121)\n",
    "plt.pcolormesh(train_X[0,:,:], cmap='jet')\n",
    "plt.title(\"Ground Truth: {}\".format(train_Y[0]))\n",
    "\n",
    "# Display second image in testing set\n",
    "plt.subplot(122)\n",
    "plt.pcolormesh(test_X[1], cmap='jet')\n",
    "plt.title(\"Ground Truth: {}\".format(test_Y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3681, 16, 40, 1), (410, 16, 40, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydim = train_X[0].shape[0]\n",
    "xdim = train_X[0].shape[1]\n",
    "train_X = train_X.reshape(-1, ydim, xdim, 1)\n",
    "test_X = test_X.reshape(-1, ydim, xdim, 1)\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label:  0\n",
      "After conversion to one-hot:  [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Change labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# See the difference?\n",
    "print('Original label: ', train_Y[0])\n",
    "print('After conversion to one-hot: ', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3681, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2944, 16, 40, 1), (737, 16, 40, 1), (2944, 2), (737, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partition data for 80% training and 20% validation\n",
    "# should reduce overfitting and boost test performance\n",
    "\n",
    "train_X, valid_X, train_label, valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2)\n",
    "\n",
    "train_X.shape, valid_X.shape, train_label.shape, valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get down to business\n",
    "import keras\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 50\n",
    "num_classes = nClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "emg_model = Sequential()\n",
    "emg_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(ydim, xdim, 1)))\n",
    "emg_model.add(BatchNormalization())\n",
    "\n",
    "emg_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "emg_model.add(BatchNormalization())\n",
    "emg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emg_model.add(Dropout(0.25))\n",
    "\n",
    "emg_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emg_model.add(BatchNormalization())\n",
    "emg_model.add(Dropout(0.25))\n",
    "\n",
    "emg_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emg_model.add(BatchNormalization())\n",
    "emg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emg_model.add(Dropout(0.4))\n",
    "\n",
    "emg_model.add(Flatten())\n",
    "\n",
    "\"\"\"emg_model.add(Dense(512, activation='relu'))\n",
    "emg_model.add(BatchNormalization())\n",
    "emg_model.add(Dropout(0.3))\"\"\"\n",
    "\n",
    "emg_model.add(Dense(128, activation='relu'))\n",
    "emg_model.add(BatchNormalization())\n",
    "emg_model.add(Dropout(0.3))\n",
    "\n",
    "emg_model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 38, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 38, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 36, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 18, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 18, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 16, 64)         18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 16, 64)         256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 16, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 14, 128)        73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 14, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               114816    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 218,530\n",
      "Trainable params: 217,762\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2944 samples, validate on 737 samples\n",
      "Epoch 1/50\n",
      "2944/2944 [==============================] - 8s 3ms/step - loss: 0.6902 - accuracy: 0.7177 - val_loss: 0.6930 - val_accuracy: 0.5034\n",
      "Epoch 2/50\n",
      "2944/2944 [==============================] - 4s 1ms/step - loss: 0.4072 - accuracy: 0.8519 - val_loss: 0.6930 - val_accuracy: 0.5020\n",
      "Epoch 3/50\n",
      "2944/2944 [==============================] - 4s 2ms/step - loss: 0.3284 - accuracy: 0.8862 - val_loss: 0.7073 - val_accuracy: 0.4966\n",
      "Epoch 4/50\n",
      "2944/2944 [==============================] - 4s 1ms/step - loss: 0.2645 - accuracy: 0.9073 - val_loss: 0.7539 - val_accuracy: 0.4966\n",
      "Epoch 5/50\n",
      "2944/2944 [==============================] - 4s 1ms/step - loss: 0.2402 - accuracy: 0.9209 - val_loss: 0.8315 - val_accuracy: 0.4966\n",
      "Epoch 6/50\n",
      "2944/2944 [==============================] - 4s 1ms/step - loss: 0.2257 - accuracy: 0.9239 - val_loss: 1.0093 - val_accuracy: 0.4966\n",
      "Epoch 7/50\n",
      "2944/2944 [==============================] - 4s 1ms/step - loss: 0.1907 - accuracy: 0.9310 - val_loss: 1.2570 - val_accuracy: 0.4966\n",
      "Epoch 8/50\n",
      "1280/2944 [============>.................] - ETA: 2s - loss: 0.1670 - accuracy: 0.9414"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-95e9d27909fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(valid_X, valid_label))\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/opt/miniconda3/envs/trial_env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_emg = emg_model.fit(train_X,train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
